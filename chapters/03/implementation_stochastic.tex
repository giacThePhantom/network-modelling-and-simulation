\graphicspath{{chapters/03/images/}}
\chapter{Implementation of the Stochastic Simulation Algorithms}

\section{Introduction}

  \subsection{Non-deterministic vs stochastic}
  Working under the assumption of using the same model and parameters:

  \begin{multicols}{2}
    \begin{itemize}
      \item A deterministic system does not show randomness and the same result is always obtained.
      \item A non-deterministic system shows some degree of uncertainty: different runs have different results.
    \end{itemize}
  \end{multicols}

    \subsubsection{Exact stochastic simulation}
    In an exact stochastic simulation, if some hypotheses are satisfied the system will behave like the biological one.
    Although the probability function could be computed, this does not make the method deterministic: uncertainty is intrinsic in the model.
    Theoretically there is no insight on the execution of the reactions in a stochastic setting, but a high level of accuracy can be reached thanks to the probability function.

  \subsection{Advantages of a non-deterministic approach}
  The reasoning behind the employment of a non-deterministic approach lies in the fact that to model a biological system there is a need to compromise between time and complexity.
  In non-deterministic polynomial time algorithms don't have an efficient solution, but it seems possible to find it.
  A non-deterministic setting allows us to understand whether an algorithm can be solved in polynomial time by step-wise guessing.

  \subsection{Categories of the exact simulation algorithms}
  A summary of the main exact stochastic simulation algorithms is reported in figure \ref{fig:tree}.

  \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{tree_methods.png}
    \caption{Fig 3.1 Marchetti's book}
    \label{fig:tree}
  \end{figure}

\section{Direct method}
Gillespie's direct method defines a couple of formulae able to understand how the system will execute in terms of time $\tau$ and reactions $\mu$.
Since each time step is infinitesimal each reaction occurs and ends exactly at time $\tau$, hence there cannot be multiple reactions firing simultaneously.
Let $a_0$ be the sum of all propensities in the system, then the algorithm works as follow:

\begin{enumerate}
  \item Sample one random number from the distribution $a_0 = \sum_{j=1}^{M}{a_j}\rightarrow V_1=U(0,1)$.
  \item Scale it to the maximum $V_1 \cdot a_0 =U(0,a_0)$.
  \item See where this number will point over the different propensities ( Figure \ref{fig:boundaries}).

    \begin{figure}[H]
      \centering
      \includegraphics[width=\textwidth]{boundaries.png}
      \caption{Fig 3.2}
      \label{fig:boundaries}
    \end{figure}

  \item Generate another random number $V_2 =U(0,1)$ \item $\tau \sim Exp(a_0)$ \item $\tau = \frac{1}{a_0}ln(\frac{1}{V_2})$.
\end{enumerate}

  \subsection{Mathematical discussion}
  Gillespie's direct method is used to sample the pdf $p(\tau, \mu|\vec{x},t)$.
  The direct method partitions the joint probability density function into the product of two one-variable probability functions, one for $\tau$ and one for $\mu$ that can be sampled independently.
  The pdf can be factorized by the chain rule of probability as:

  $$p(\tau, \mu|\vec{x},t) = p_1(\tau|\vec{x},t)p_2(\mu|\vec{x},t)$$

  Where:

  \begin{multicols}{2}
    \begin{itemize}
      \item $p_1$ is the probability density function of the firing time $\tau$.
      \item $p_2$ is the probability density function of the reaction with index $\mu$ that fires at $t+\tau$.
    \end{itemize}
  \end{multicols}

  So that $p_1(\tau|\vec{x},t)d\tau$ is the probability that a reaction will fire in the next time interval $[t+\tau, t+\tau+d\tau[$.
  This marginal probability is obtained by summing the probability $p(\tau, \mu|\vec{x},t)d\tau$ over the domain of all possible values of reaction index $\mu$:

  $$p(\tau|\vec{x},t) = \sum\limits_{\mu=1}^Mp(\tau, \mu|\vec{x},t) = \sum\limits_{\mu=1}^Ma_\mu e^{a_0\tau} = a_0e^{-a_0\tau}$$

  Where $a_0$ is the total propensity.
  Plugging this and recalling the formula of the joint pdf:

  $$p_2(\mu|\tau,\vec{x},t) = \frac{p(\tau,\mu|\vec{x},t)}{p_1(\tau|\vec{x},t)} = \frac{a_\mu}{a_0}$$

  It can be seen how $p_2$ is independent of $\tau$, so it can be written as:

  $$p_2(\mu|\vec{x},t) = p_2(\mu|\tau,\vec{x},t) = \frac{a_\mu}{a_0}$$

  To verify that these two equation are part of the pdf:

  $$\int_0^{\infty}p_1(\tau|\vec{x},t)d\tau = \int_0^{\infty}a_0e^{-a_0\tau}d\tau = 1 \qquad\land\qquad \sum\limits_{\mu=1}^Mp_2(\mu|\vec{x},t) = \sum\limits_{\mu=1}^M\frac{a_\mu}{a_0} = 1$$

  The direct method uses $p_1(\tau|\vec{x},t)$ to sample the firing time $\tau$ and $p_2(\mu|\vec{x},t)$ to sample the reaction index $\mu$.
  Since the two pdfs are independent the firing time and the reaction index can be sampled independently, so that the order of sampling does not effect the exactness of the direct method.
  The generated firing time $\tau$ and the next reaction firing $R_\mu$ are ensured to have the pdf $p(\tau,\mu|\vec{x},t)$ specified by the stochastic simulation algorithm, so that the generated trajectories are exact.

    \subsubsection{Choice of the reaction}
    The selection of the next reaction index $\mu$ has probability $\frac{a_\mu}{a_0}$.
    Given $M$ discrete probabilities $\frac{a_j}{a_0}$ with $j = 1,\dots, M$, the choice of the next reaction index:

    \begin{align*}
      \mu &= \arg\min\limits_{\mu\in j=1,\dots,M}\sum\limits_{j=1}^M\frac{a_j}{a_0}\ge r_1 =\\
        &= \arg\min\limits_{\mu\in j=1,\dots,M}\sum\limits_{j=1}^Ma_j\ge r_1a_0
    \end{align*}

    Where $r_1$ is a uniformly distributed random number $norm(0,1)$.
    To select the next reaction firing $R_\mu$, the direct methods accumulates the sum $\sum\limits_{j=1}^\mu a_j$ until it finds the smallest index $\mu$ that satisfies that inequality.

    \subsubsection{Selection of the firing time}
    For the reaction of the firing time $\tau$, consider its pdf $p_1(\tau|\vec{x},t)$.
    It can be noted ho it is an exponential distribution with rate $a_0$.
    So the firing time can be generated as:

    $$\tau = \frac{1}{a_0}\ln\frac{1}{r_2}$$

    Where $r_2$ is a uniformly distributed random number $norm(0,1)$.

  \subsection{The algorithm}
  The independent sampling of the firing time and of the reaction index are the basis of each simulation step of the direct method, outlined in algorithm \ref{algo:dm}.

  \input{chapters/03/algorithms/dm}

  Lines $10$-$12$ implement the sampling of the joint reaction probability density function of the next reaction firing and its firign time.
  The simulation needs two random number, the first is used to select the next reaction firing with probability $\frac{a_\mu}{a_0}$, while the second for the firing tiem.
  The state is then advanced to the new one and the time is moved to $t+\tau$.

    \subsubsection{Time complexity}
    The computational cost for the generation of random numbers, the firing time and the update of simulation time are constant.
    Moreover the update of the state can be considered constant as only a few species are involved in a reaction.
    Because of this the computational cost of the algorithm arises due to:

    \begin{multicols}{2}
      \begin{itemize}
        \item The computation of reaction propensities due to state changes at lines $7$-$9$.
        \item The selection of the next reaction firing at line $11$.
      \end{itemize}
    \end{multicols}

    The direct method computes $M$ reaction propensities for each simulation step, so the time complexity for this step is of $O(M)$.
    The search for the next reaction in the worst case requires to sum up all the $M$ reaction propensities, making the cost for searching the next reaction firing $O(M)$.
    Summing up the time complexity for each simulation step of the direct method is $O(M)$.

  \subsection{Enhanced direct method}
  The enhanced direct method EDM reduces the number of propensity computation for each simulation iteration, recomputing only the propensity of reactions that change.
  The detection of changes in the reaction propensity is based on the fact that the propensity of a reaction changes only when the population of the reactants involved in the reaction changes only then the population of the reactants involved are changed by the reaction firing.
  Only the propensity of reaction that have reactant population changed are recomputed.
  This is decided by analysing the dependency relationship between reactions.

    \subsubsection{Reaction dependency graph}
    A reaction $R_j$ is dependent on a reaction $R_\mu$ if its propensity $a_j$ is changed when $R_\mu$ fires.
    This relationship is collected and presented in a reaction dependency graph.

      \paragraph{Some definitions}

        \subparagraph{Reactants and products set}
        For each reaction $R_j$, with $j = 1,\dots M$, define:

        $$Reactants(R_j) = \{S_i|S_i\text{ is a reactant of }R_j\}\qquad\land\qquad Products(R_j) = \{S_i|S_i\text{ is a product of }R_j\}$$

        \subparagraph{Affects set}
        The set of species involved in the computation of the propensity $a_j$ of a reaction $R_j$ is:

        $$Affects(R_j) = \{S_i|a_j\text{ changes if population of }S_i\text{ changes}\}$$

        \subparagraph{Mass action kinetics}
        For mass action kinetics, because the mass action propensity $a_j$ of reaction $R_j$ is proportional to its reactants:

        $$Affects(R_j) = Reactants(R_j)$$

        \subparagraph{AffectedBy set}
        The set of species whose population changes by firing reaction $R_j$ is:

        $$AffectedBy(R_j) = \{S_i|\text{Population of }S_i\text{ is changed if firing }R_j\}$$

        \subparagraph{Population of AffectedBy}
        For each reaction $R_j$ it is:

        $$AffectedBy(R_j)\subseteq Reactants(R_j)\cup Products(R_j)$$

        This is because $AffectedBy(R_j)$ includes species that are consumed and produced by reaction $R_j$ excluding any species whose population is conserved.

      \paragraph{Definition of the reaction dependency graph}
      Let $\mathcal{R}$ be the set of reactions in the biochemical reaction network.
      The reaction dependency graph $G(V, E)$ is a directed graph with the vertex set $V = \mathcal{R}$ and the edge set $E$ contains directed edges $e(R_j, R_k)$ from a reaction $R_j$ to another reaction $R_k$ if:

      $$AffectedBy(R_j)\cap Affects(R_k)\neq\emptyset$$

      All self-edges $e(R_j, R_j)$ belong to $E$.

      \paragraph{Dependent reactions}
      The set of reactions that are dependent on reaction $R_j$ by the reaction dependency graph $G$ is defined such that:

      $$Dependents(R_j) = \{R_k|\exists\text{ a directed edge }e(R_j,R_k)\in G\}$$

      The reaction dependency graph $G$ determines the reaction for which propensities must be recomputed after firing.
      The number of reaction in the $Dependents$ set is equal to the out-degree of the reaction in the dependency graph.

    \subsubsection{Algorithm}
    In the EDM algorithm the reaction dependency graph is the first thing built.
    This will be a static structure independent on the time evolution of the system and will be stored with a cost $O(M^2)$.
    The computation of propensity of all the reaction is performed only at the beginning of the simulation.
    For each iteration the selection is the same as in DM, then the new propensity for each reaction $R_j\in Dependents(R_\mu)$ is computed.
    The algorithm is presented in \ref{algo:edm}.

    \input{chapters/03/algorithms/edm}

    In this way the propensity updates become local.
    Let $D$ be the average number of reactions depending in a reaction, the cost of the propensity update for a simulation loop becomes $O(D)$, considering that $D<M$, so the propensity update in EDM is more efficient than in DM.

  \subsection{Improvements for Direct Method}

    \subsubsection{Direct method with sorted reaction}
    The principle of the direct method with sorted reaction is to reduce the search depth of the direct method by re-indexing reactions, reducing the search depth of reactions that happens more frequently, improving simulation performance.

      \paragraph{Optimized direct method}
      The optimized direct method reduces the average search depth of the next reaction firing.
      This is done because in many biochemical networks, some reactions fire much more frequently tan others.

        \subparagraph{Average search depth}
        The average search depth $S_m$ is the average number of operation performed for the selection of the next reaction firing:

        $$S_M = \frac{\sum\limits_{j=1}^Mjn_j}{\sum\limits_{j=1}^Mn_j}$$

        Where:

        \begin{multicols}{2}
          \begin{itemize}
            \item $j$ is the search index of reaction $R_j$.
            \item $n_j$ is the number of times that $R_j$ fires during the simulation.
          \end{itemize}
        \end{multicols}

        These two values are not known so to order the reactions $\langle n_j\rangle$ the average estimation of $n_j$ is used to order reaction.
        This is computed by some short pre-simulation runs.

        \subparagraph{Algorithm}
        Optimized direct method is implemented as in algorithm \ref{algo:odm}.

        \input{chapters/03/algorithms/odm}

        \subparagraph{Discussion}
        In the case of a fixed number of bits the sum of the biggest propensities placed in the front of the search list may be not enough to account for the rest: the reactions with very small propensity will never fire.
        Moreover the pre-simulation introduces an additional computational burden to the simulation.
        Moreover ODM assumes that the reaction order determined by the pre-simulation runs will characterize the long-term reaction behaviour, which could not be true.

      \paragraph{Sorting direct method}
      The sorting direct method SDM is a variant of ODM that does not use pre-simulation runs by maintaining an approximately sorted order of reaction.
      The ordering is built dynamically during the simulation run: the index of a reaction whenever it is selected to fire is dynamically bubbled up one step ahead in the reaction list.
      The reactions that have just occurred are put towards the top of the search list.

        \subparagraph{Algorithm}
        The sorting direct method is implemented as in algorithm \ref{algo:sdm}.

        \input{chapters/03/algorithms/sdm}

        \subparagraph{Discussion}
        The swapping step adds overhead to each simulation step, but it is negligible.
        SDM is thus suited to deal with the simulation of networks where the propensities change sharply.

    \subsubsection{Direct method with Multi-level search}
    The mani bottleneck of DM is that the search for next reaction firing is slow in large reaction models.
    The multi-level search is an effort to reduce the time complexity of DM for large systems.
    The search problem is divided into smaller sub-problem partitioning the $M$ reactions into $L$ groups $G_1, \dots, G_L$.
    Each group $G_l$ contains $k_l$ reactions.
    Let $a^l$ be the sum of propensities of reactions in group $G_l$:

    $$a^l = \sum\limits_{R_j\in G_l}a_j$$

    It is obvious that:

    $$a_0 = \sum\limits_{l=1}^L a^l$$

    The selection of the next reaction firing is in two steps.
    First a group $G_\alpha$ is selected with probability $\frac{a^\alpha}{a_0}$.
    Then the next reaction firing $R_\mu$ is selected with probability $\frac{a_\mu}{a^\alpha}$ conditioning on the selected group $G_\alpha$.

      \paragraph{Exactness of the multi level search}
      The next reaction $R_\mu$ in the group $G_\alpha$ that is selected by the multi-level search has probability $\frac{a_\mu}{a_0}$.
      Let $\mathbb{P}\{R_\mu\}$ be the probability of selecting the reaction $R_\mu$.
      This can be expanded as:

      $$\mathbb{P}\{R_\mu\} = \mathbb{P}\{G_\alpha\}\mathbb{P}\{R_\mu|G_\alpha\} = \frac{a^\alpha}{a_0}\frac{a_\mu}{a^\alpha} = \frac{a_\mu}{a_0}$$

      \paragraph{Implementation}
      An implementation to select the group index and the reaction index requires two random numbers:

      $$\alpha = \arg\min\limits_{\alpha\in l = 1, \dots, L}\sum\limits_{l=1}^\alpha a^l\ge r_1a_0$$

      And:

      $$\mu = \arg\min\limits_{\mu\in k = 1, \dots, M}\sum\limits_{\substack{k=1\\G_\alpha = \{R_j, \dots, R_{j+k\alpha}\}}}^\mu a_k\ge r_2 a^\alpha$$

      The need  for $r_2$ can be avoided by recycling $r_1$:

      $$\frac{r_1 a_0 -\sum\limits_{l=1}^{\alpha-1}a^l}{a^\alpha}$$

      Is a uniformly distributed random number.
      SO $r_1$ is rescaled to select the next reaction firing in the group.

      \paragraph{Algorithm}
      The direct method with multi-level search is implemented as in algorithm \ref{algo:dm-multi-level}.

      \input{chapters/03/algorithms/dm-multi-level}

      \paragraph{Discussion}
      To analyse the time complexity of the multi-level search assume that $M$ reactions are partitioned into $L = \left[\frac{M}{k}\right]$ groups and each group contains $k_l=k$ reactions.
      The time complexity has two parts:

      \begin{multicols}{2}
        \begin{itemize}
          \item Searching for a group $O\left(\frac{M}{k}\right)$.
          \item Searching for a reaction within the group $O(k)$.
        \end{itemize}
      \end{multicols}

      The total time complexity is then

      $$O\left(\frac{M}{k}\right) + O(k) = O(\max\left\{\frac{M}{k}, k\right\})$$

      The total time is minimized by taking $k = c\sqrt{M}$, so that the minimal time complexity per reaction event is $O(\sqrt{M})$.
      The multi-level search can be further expanded partitioning the groups into sub-groups, introducing the multi-dimensional search method.




















\section{First Reaction Method (FRM)}
Instead of computing one $\tau$, compute a $\tau$ for each reaction (Figure \ref{fig:tau}).
Example: $\tau_1 = Exp(a_1)=1/a_1ln(1/V_1)$.
We are assuming that no other reactions are firing in the middle.
We can generate M random numbers and end up with M $\tau$.
Then we choose the reaction with minimum $\tau$, which will be the first selected one.
$\mu= R_{\mu}\text{ st }\tau_{\mu}= \min_{j}\tau_j$

 \begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{R_tau.png}
    \caption{R Tau}
    \label{fig:tau}
  \end{figure}

\begin{itemize}
\item Pro: sometimes the search is quicker, simpler to parallelize.
\item Cons: we generate a lot of random numbers with respect to the direct method.
\end{itemize}

After the first step, we need to recompute. Even here, there is the possibility to improve the algorithm e.g.computation of the propensity.

\section{First Family Method}
Tries to combine the good features of the direct method with the first reaction method.
The idea is to reach an implementation which can be partially parallelizable: divide the reaction in ``families'' or groups.
The idea is to divide the reaction in n groups $r_1,…r_n$ and families e.g.~3 families.
We should associate a theoretical propensity to each group, i.e. the sum of the propensity in the family $a^1=\sum_{j\in f_1}a_j$.
$FRM= \tau_1= \frac{1}{e^1}ln(\frac{1}{r_1})$, we do not know which one of the reactions will be applied.
\\
\\
\noindent
In order to decide, we apply the direct reaction method formula for selecting the index.
Given that we are working with a subset, we will scale over the sum, the $a_0$ of the group.
It is true that we are generating random numbers, but over the number of the families → reduction.
This time we have n families + 1 random number to select the family.
Danger: if we have big disequilibrium in propensity, we might end up selecting always one of the families.
We can parallelize by linking families to CPU.
\\
\\
\noindent
Last time, we were introducing Next Reaction Method, which can be considered as an evolution, trying to apply the same reasoning as FRM in a more efficient way (by applying an efficient handling of random numbers).
If we are able to do so we will need to compute less random numbers.
DM → $2 \cdot n_{steps}$ FRM → $M \cdot n_{steps}$ FFM → $(n_{families}+ 1)n_{steps}$ NRM → $M+n_{steps}$.
If we take a look at the difference among methods, it is not very clear which is the winner - even though NRM seems to be one of the most optimized, it is usually the most efficient in requiring less random numbers.
Of course everything has a price, we need to add computations.
NRM is the most efficient in random number generation, while FRM is the one consuming the most.

\section{Next Reaction Method}
Why do we need to recompute time points? Two issues:

\begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item multiple reactions can be executed at the same time → the reaction propensities might change \item we are computing $\tau$ over propensities, but the propensities were computed on initial reaction settings.
  E.g.$R_2:A \rightarrow B$, $R_1 : A \rightarrow B$ , the two reactions depend on each other.
\end{enumerate}

\noindent
$\tau$ is modelling the instant in which the reaction is assumed to fire, it is just an event.
We can subtract the time for passing to following reactions, but we must also update the propensity.
$a_1 \rightarrow a_1^{new}$, we have three possibilities:

\begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item $a_1 = a_1^{new}$. $R_2$ is not affecting the propensity, i.e.~reactant is not modified by $R_2$, so $R_1$ remains unchanged.
  \item $a_2^{new}> a_1$. $R_2$ has been applied, something has changed and the firing prob of $R_1$ is increasing.
    Therefore, $\tau_1$ needs to be updated, we expect it to be smaller → rescaling through the ratio of the propensities e.g. ~$(\tau_1-\tau_2) \cdot \frac{a_1}{a_1^{new}}$ \item $a_1^{new}< a_2$ higher $\tau_1$
\end{enumerate}
\noindent
We should not think of another event, we are just updating the same event through the formula! The algorithm was developed in the 2000s, there are a lot of improvements related to technology advancements.
In addition to rescaling formula, there are other improvements to keep the complexity of the algorithm as low as possible:

\begin{itemize}
  \item we avoid generating too many random numbers
  \item reaction dependency graph (introduced for Direct Method): recompute the propensity of the reaction only if it is needed
  \item searching the reaction: minimum is linear over the number of reactions.
    \textbf{Binary heap}: decrease to logarithmic scale, select winner in constant time.
\end{itemize}
\noindent
Gibson 2000: original paper Thanh 2014: latest algorithm.

\section{RSSA}
The Rejection-based Simulation Algorithm seems to be an approximation, but everything is exact.
It tries to reduce computation complexity, but instead of limiting the amount of random numbers, it focuses on another bottleneck: the computation of the reaction propensity.
\\
\\
\noindent
The computational problem becomes more complex if we do not rely on mass action.
The RSSA Algorithm therefore tries to reduce the number of times in which we compute the reaction propensity.
We will need a placeholder and at the same time to keep the computation exact.
Instead of using the state of the system, we use a \textbf{\emph{fluctuation interval}}(a bound).
From the state of the system $X$ we generate a lower and upper bound; to do so, we just use a parameter providing a percentage, which is called $\delta$ ($0<\delta<1$).
Therefore, the bounds will be computed as:

\begin{itemize}
  \item lower $X = X - X \cdot \delta$ \item upper $X = X + X \cdot \delta$
\end{itemize}

\noindent
Given that the events of the reaction are modifying a few molecules per time, we can assume that for a certain amount of steps we will remain inside the same range of variability.
We are trying to obtain a propensity computed over bounds; by doing so, we can apply the same computation for a higher number of steps, as we only need to recompute the propensity outside of the fluctuation interval.
We can also compute the upper bound for the sum of the propensities $\bar{a}_0$.
$a_1$ will be in the middle, but we do not want to compute it.
It seems like working with these bounds does not lead to an exact simulation: we need to avoid as much as possible the exact computation of the propensities.
\\
\\
\noindent
Indeed, in the vast majority of cases we will have the possibility to choose the reaction without the real propensity.
We will perform some computations and, given the presence of bounds, we will do some mistakes; the algorithm will evaluate the results and eventually reject them (rejection-based algorithm).
For doing so, the algorithm generates the events with the upper bound of the propensity $\bar{a}_0$.
By using an upper bound $\tau$ will be lower, so we will generate more events with respect to the direct method.
We apply a sort of Gillespie, we replace the standard propensity with the upper bound and choose the reaction as in the direct method.
How can we understand whether an event is real or fake? In the case in which $\bar{a}_0 = a_0$ we are in the standard Gillespie.
We should apply a similar reasoning as NRM for scaling for checking the validity of candidate reactions.
\\
\\
\noindent
Let's imagine that we are selecting $R_2$: we should generate another random number, scale it over the bound and understand if we are in the exceeding (fake) or inside (real) area.

\begin{itemize}
  \item If the random number is lower than the lower bound, we can accept it without computing the real propensity.
  \item If the random number is between the bounds we require the exact propensity for discriminating:

  \begin{itemize}
    \item $\underline{a}_2 < u < a_2$ accept \item $a_2 < u < \bar{a}_2$ reject
  \end{itemize}

\end{itemize}

\noindent
The higher the fluctuation interval, the higher the uncertainty but lower the complexity → find the right compromise with some heuristics on $\delta$ value.
