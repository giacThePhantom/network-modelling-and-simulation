\graphicspath{{chapters/06/images/}}
\chapter{Hybrid simulation approaches}

\section{Introduction}
Hybrid simulation approaches refer to a class of methods that combines the advantages of complementary simulation approaches: the system is partitioned into subsystems that are simulated with different methods.
When exact stochastic simulation is not a realistic option approximate strategies have to be considered together with their accuracy, so they often require the fulfilment of specific conditions.
The state space associated with biochemical reaction networks can be partitioned into regions depending on the nature of the system, according to the number of molecules and the frequency of reaction events.
This helps evaluate which approximations are reasonable.
The essential elements are the abundance of the species and the frequency of reaction.
Threshold variables demarcate the different partitions and they are model dependents as seen in figure \ref{fig:regions}:

\begin{multicols}{2}
  \begin{itemize}
    \item $t_1$ indicates whether a reaction is considered fast.
    \item $t_2$ indicates whether a population is abundant or not.
    \item $t_3$ and $t_4$ the border between stochastic variation and deterministic behaviour.
  \end{itemize}
\end{multicols}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{regions.png}
  \caption{Partitions of the state space}
  \label{fig:regions}
\end{figure}

  \subsection{Slow-discrete region}
  The system is in a slow-discrete region when the reaction are slow and low numbered species are present.
  The species must be represented with an integer and discrete changes are allowed.
  Moreover the reaction events are rare and correspond to significant changes in the system.
  This region should be treated with the highest accuracy method available.

  \subsection{Fast-discrete region}
  The system is in the fast-discrete region whenever molecular populations are small and the reactions happen frequently enough that exact simulation could be intractable.
  This region can be treated with stochastic approximate algorithms developed to work with large reaction propensities and small populations like BA-RSSA.

  \subsection{Slow-continuous region}
  The system is in the slow-continuous region whenever molecular population are large and reaction are slow.
  The molecular populations can be assumed continuous and each reaction occurrence does not change significantly its species concentration.
  The simulation of many reaction occurrences can be skipped without affecting the accuracy.
  This region can be treated by the $\tau$-leaping algorithm.

  \subsection{Fast continuous stochastic and deterministic region}
  The system starts in the fast continuous stochastic and goes into the deterministic whenever it has fast reactions and high number species.
  In the first case the CLE can be considered for the simulation, while in the second deterministic simulations can be used.

  \subsection{Dimensionality explosion}
  The system is two dimensional only when it has one species and one reaction.
  When these two sets increase the criteria above can be applied only when all of them belong to the same region.
  This is a very strict condition that must be preserved along all of the simulation process.
  Hybrid simulation approaches try to solve this problem by dividing the system into parts that fit with the regions described which are then simulated by ad hoc simulation methods to provide the best compromise between accuracy and runtime.

\section{Reaction-based system partitioning}
The reaction based system partitioning partitions the system into subnetwork that reaquire to be simulated by the same strategy.
The reaction are divided into $\mathcal{R}^s$ and $\mathcal{R}^f$ of slow and fast reactions.
Fast reaction have high propensities and can be simulated by CLE or deterministic simulation while slow one have low propensities.
When deterministic simulation is employed a preliminary step is required to transform the set of reactions in ODEs.
Slow reactions require a more accurate stochastic simulation approache.

  \subsection{Classifying fast reactions}
  Reactions can be fast when it occurs many times in a small time interval and the effect of each reaction on the number of reactants and products is small, so quantitatively:

  $$a_j\tau^f \ge \theta\ll 1$$

  And:

  $$\vec{x}_i > \lambda|\vec{v}_{ij}|, \forall S_i\in Reactants(R_j)\cup Products(R_j)$$

  $\theta$ and $\lambda$ define the minimum number of time a fast reaction can be applied within $\tau^f$ and how fine grained the species must be in order for them to appear as continuous.
Usually for practical models $\theta = 10$ and $\lambda = 100$.

  \subsection{Partitioning algorithm}
  An implementation of this reaction-based partitioning can be found in algorithm \ref{algo:two-class-reaction-partitioning}

  \input{chapters/06/algorithms/two-class-reaction-partitioning}

  \subsection{Dynamic partitioning}
  Because reaction propensities and state vector change in time the partitioning has to be evaluated during the simulation.
  This is dynamic partitioning.
  It is important when the system state varies considerably over time.
  A fixed partitioning can be used  when the subsystems are different and these differences remain constant during the simulation.

  \subsection{Different constraints}
  Some partitioning strategies depends only on the second condition and relax it to include only the reactants.
  This is to speed up the simulation by taking out the stochastically simulated fast reaction subsystem, while particle-number based partitioning is concerned with correctly treating reactions with small concentrations.
  Moreover $\tau^f$ can change at each simulation step and can be not considered: the reaction are divided into a tentative partitioning and then a fixed point iterative scheme happens, tuning the partitioning so that the propensity of each fast reaction will be at least $\lambda$ times larger than the fastest slow reaction.
  This procedure, outlined in algorithm \ref{algo:two-class-reaction-fixed-point} is more computationally demanding but has less parameters.

  \input{chapters/06/algorithms/two-class-reaction-fixed-point}

  \subsection{Four class reaction partitioning}
  The reaction partitioning in two classes reduces at minimum the simulation strategies implemented in the hybrid algorithm, simplifying its implementation, but reducing the accuracy of the results.
  A higher number of reaction classes are introduced to be more consistent with the regions.
  A way of doing so is to divide it into fours set:

  \begin{multicols}{2}
    \begin{itemize}
      \item Very slow reactions $\mathcal{R}^{vs}$ requiring exact simulation.
      \item Slow reactions $\mathcal{R}^s$ requiring a $\tau$-leaping method.
      \item Medium reactions $\mathcal{R}^m$, requiring CLE.
      \item Fast reactions $\mathcal{R}^f$, requiring deterministic simulation.
    \end{itemize}
  \end{multicols}

  At the basis of this strategy is the computation of $\tau$, providing the next firing time of a model reaction and imposing the following restraints:

  \begin{itemize}
    \item $a_j\tau\le 1$ $R_j$ very slow.
    \item $a_j\tau > 1\land a_j\tau\not\gg 1$ $R_j$ is slow.
    \item $a_j\tau\gg 1\land\sqrt{a_j\tau}\not\gg 1$ $R_j$ is medium.
    \item $\sqrt{a_j\tau}\gg 1$ $R_j$ is fast.
  \end{itemize}

    \subsubsection{Algorithm}
    An implementation of the four class reaction based partitioning is outlined in algorithm \ref{algo:four-class-reaction}, introducing $\theta$ to implement the $\gg$ constraint

    \input{chapters/06/algorithms/four-class-reaction}

\section{Synchronization of exact and approximate simulations}
When the hybrid strategy moves forward one simulation step, slow reaction are simulated by exact stochastic simulation while less accurate strategies are used for faster reactions.
The approximate simulation of faster reactions is constrained to not exceed the firing time of the first slow reaction.
This is a synchronization to preserve the accuracy of the simulation.
Even if the simulation of slow reactions is exact, their firing is not guaranteed to be exact when faster reactions are simulated in an approximate way.
Since the approximation is difficult to obtain many hybrid algorithm implement a simulation for slow reactions that is not exact, but less approximate than the one of the fast reactions.

  \subsection{Algorithm}
  An implementation of a four class hybrid simulation strategy is implemented in algorithm \ref{algo:four-class-hybrid-simulation}.

  \input{chapters/06/algorithms/four-class-hybrid-simulation}

  \subsection{Preserving the exactness}
  In order to preserve the exactness of the simulation of slow reactions, the reaction probability density has to be extended to consider time-varying transition propensities account for the propensities of slow reactions that change due to the simulation of fast reactions.
  The pdf of the next firing of a slow reaction $R_\mu\in\mathcal{R}^s$ becomes:

  $$p^s(\tau, \mu|\vec{x}, t) = a_\mu(X(t+\tau))e^{-\int_t^{t+\tau}a_0^s(X(t'))dt'}$$

  Where $X(t+\tau)$ is the system at time $t+\tau$, $\vec{x}$ is the current system state and:

  $$a_0^s = \sum\limits_{R_j\in\mathcal{R}^s}a_j$$

  The firing time of the next slow reaction is obtained by solving:

  $$\int_t^{t+\tau} a_0^s(X(t'))dt' = -\ln(r)$$

  This solution is difficult to compute: the system state is changed by fast reactions during the time interval.
  The hybrid simulation has to evaluate it simultaneously with the simulation of the fast reaction to generate the next slow reaction event.

    \subsubsection{Event detection}
    In order to satisfy the time integral the simulation of fast reaction has to include an event detection part.
    The easiest way to do so is to relax the constraint of the equation to find a time instant along the simulation such that:

    $$\biggr\vert\int_t^{t+\tau}a_0^x(X(t'))dt' + \ln(r)\biggr\vert\le\epsilon$$

    Where $\epsilon\approx 0$ is a positive error threshold.
    This makes the simulation of slow reaction depend on $\epsilon$.
    This correspond to adding to the set of deterministic ODEs an additional equation:

    $$\frac{dRES}{dt} = a_0^xRES(0) = \ln(r)$$

    This is numerically integrated together with the set of ODE until $|RES(t+\tau)|\le\epsilon$.
    The computation of the firing time of the next slow reaction will be not exact because it depends on the order of the numerical method used to solve the initial value problem.

    \subsubsection{Algorithm}
    A two class hybrid strategy with exact simulation of slow reactions is outlined in algorithm \ref{algo:two-class-hybrid-exact-slow}

    \input{chapters/06/algorithms/two-class-hybrid-exact-slow}

\section{Hybrid Rejection-Based SSA}




\section{Reaction-Based System Partitioning}
In order to divide reactions into group we can set up a threshold, which could be computed over the product of the propensity of the state and the simulation step.
If the product is higher or lower than the threshold, we can identify the reaction as rare or probable.
Example of partitioning algorithm: \emph{two class reaction-based partitioning}.
Divide reactions in slow and fast through an iterative loop.
In general, we can increase the complexity of such approach as much as we want.
Example: \emph{four class reaction based partitioning}, we can bridge more simulation strategies.
In Algorithm 45 the four class partitioning is applied; at the very beginning we impose a time step e.g.~with tau leaping, compute the partitioning ending up with 4 sets (very slow, slow, medium and fast).
For any of the reactions we will apply different strategies, for instance in the case of the very slow we require exact stochastic simulation.
For sure the simulation will be more accurate, but we cannot claim that the simulation is exact, since we are only working on a set of reactions, not on the full system.
If we wish to have an exact algorithm, we should consider the problem of \textbf{time varying reaction propensity}.
If we want to be able to appropriately generate time, we should move considering the integral of the propensity over the time and the random number.
We can consider the zero crossing of an equation as following (the log of the random number is a negative quantity):

$$\int_t^{t+\tau}a_0^s (X(t')) dt' = - \ln(r)$$
\noindent
Instead of deciding $\tau$ at the beginning, the time will be computed along the approximation; when the quantity will be equal to zero, the approximation will stop and restart.
We can consider this as a sort of traffic light: an event is generated, green light, we can move one.
The real issue is that even if we have an equation to find the right time, being able to compute this requirement exactly with a computational strategy is a problem.
The approach to zero will be affected by a variety of steps, e.g.~the computer has a certain threshold for the zero.
In addition computing the integral is computationally challenging.

\begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item non trivial complexity, integrals tend to be approximated by computers
  \item the zero crossing is affected by approximation error
\end{enumerate}
\noindent
If we use deterministic simulation for simulating fast reactions, we can add another equation to understand when it is the time to stop during the simulation.
We start from the logarithm of the random number and proceed with numerical integration.

$$\frac{dRES}{t}= a_0^x,RES(0)= \ln(r)$$

Synchronization has a price: the more complex, the higher impact we will have on the right time.
Can we do something better? We can apply an extension of RSSA to obtain better results.

\section{HRSSA}
This algorithm claims to be exact and was developed by Marchetti.
In RSSA we have a side effect: $\tau$ is computed over an \emph{upper bound}, therefore we no longer need to reason in terms of propensity varying in time.
By taking this perspective, we totally avoid slow events, just focus on upper bound.
We have two main issues in this strategy:

\begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item by considering an upper bound we will generate more events
  \item the bounds should be satisfied, therefore along the simulations we will need to check the consistency over the fluctuation interval of the state
\end{enumerate}
\noindent
We have no need of computing the integral, we work with fluctuation intervals and link the generation of $\tau$ over this quantity, with the only difference that we only consider the upper bound and not the current value.
\\
\\
\noindent
Pseudocode (Figure \ref{fig:HRSSA}): we start from a while loop, we compute the fluctuation interval, the bounds of the propensity (same as RSSA) and move forward with $\tau$ computation.
\begin{figure}
  \centering
  \includegraphics[width=0.5\textwidth]{HRSSA.png}
  \caption{HRSSA algorithm}
  \label{fig:HRSSA}
\end{figure}
When we reach $\tau$ we decide to apply or not the reaction through random number generation.
The main issue is how to compute the reaction partitioning, in this case the algorithm divide into slow and fast.
Since we are working with bounds, we substitute the real propensity with the lower bound for performing the partitioning.
Given that the partitioning is computed on the bound, it is just necessary to compute it again for each interval â†’ speed up.
When the system is very complex, it is often not possible to apply this algorithm.

\subsubsection{HSimulator}
Simulator prototype (Java) developed by Marchetti to try HRSSA.
We simply provide the set of reactions in arrow notation, same specification as MATLAB.
The simulations provided are DM, RSSA, Euler, RK45 and HRSSA.
We have the possibility to define simulation length and time sampling i.e.~sampling over which the time series is stored.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{HRSSA_oregonator.png}
  \caption{HSimulator HRSSA Oregonator}
  \label{fig:oregonator}
\end{figure}
\noindent
\textbf{Oregonator HRSSA:} (Figure \ref{fig:oregonator})  the algorithm applies the stochastic approach by starting from the deterministic setting.
In the advanced options we can insert additional specifications{]}.
If we apply steady state conditions (simulation length = 5, time sampling = 0.
0001), we observe a flat signal; the issue is that the stochastic simulation is applied to the subset of slow reactions.
If we change the parameters for deciding if something is fast or slow, we should see a change in the behaviour.
By working with smaller variables, we see something remarkable: noise is heavily present.
